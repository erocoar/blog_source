---
title: Ordinal Logistic Regression with ggplot2
theme: hugo-kiera
author: ~
date: '2017-12-24'
categories: ["regression", "visualization", "r", "glm"]
tags: ["ggplot2", "r"]
---

Ordinal logistic regression is used to predict an ordinal response variable given one or more continuous or discrete explanatory variables. The ordinal response $Y$ could represent attitudes measured on a standard scale, ranging from e.g. "Strongly Disagree" to "Strongly Agree". $Y$ could also be constructed with a hierarchy of endpoints such as "Okay", "Good" and "Great" for rating Donald Trump's first-year presidential performance.

An advantage of the ordinal logistic model is that no spacing between the different levels of $Y$ is assumed. That is, model output would be identical for $Y$ whether it has levels $0, 1, 100$ or $0, 1, 2$. 

A popular model used for ordinal logistic regression is the Proportional Odds (PO) model, which comes with the assumption of ... proportional odds. And while there are statistical tests for the PO assumption *(see e.g. Brant, 1990)*, it is always a good idea to check visually whether it is likely to hold. 

Here, I will reproduce two plots done with `Hmisc` and `rms` packages and also do an effects plot using `ggplot2`. I won't go into much detail regarding interpretation/fit of the data I am going to use because I just wanted to see how I would plot this via `ggplot`, irrespective of specific models.

The PO model is defined as

$$logit[P(Y_i > j)] = ln \frac{P(Y_i > j)}{P(Y_i \leq j)} = (\alpha - \alpha_j) + \beta_1 X_i1 + ... + \beta_k X_ik$$
or equivalently
$$logit[P(Y_i \leq j)] = ln \frac{P(Y_i \leq j)}{P(Y_i > j)} = \alpha_j - \alpha - \beta_1 X_i1 - ... - \beta_k X_ik $$

where, then
$$P(Y \leq j) = \frac{e^{(\alpha_j - \beta x)}}{1 + e^{(\alpha_j - \beta x)}}\\P(Y \geq j) = \frac{1}{1+e^{-(\alpha_j + X\beta)}}$$

How the proportional odds model is written can vary by author. Harrell in *Regression Modeling Strategies (2001)* writes it in terms of $Y \geq j$.

The PO assumption is nicely displayed in the model already - parallel slopes for each regression equation ($j = 1, 2, ... j-1$) because for any $2$ categories $j$ and $j^*$, the cumulative logits differ only by $(\alpha_{j^*} - \alpha_j$).

$$\frac{odds_j}{odds_j^*} = exp(logit_j - logit_j^*) = exp(\alpha_j* - \alpha_j)$$

To create the plots, I use a (edited) sample of a [wine reviews dataset](https://github.com/erocoar/blog_source/blob/master/content/posts/wines.csv) from [Kaggle](https://www.kaggle.com/zynicide/wine-reviews), trying to predict reviews ranging from $0$ to $4$ (bad to good) with wine price and the state where it was produced (California, New York, Washington, Oregon).

```{r, message = FALSE, include = FALSE}
wines <- read.csv("wines.csv", sep="")
wines$points <- as.factor(wines$points)
wines$province <- as.factor(wines$province)
```

```{r}
head(wines)
```

To check the PO assumption, we can compare the means of $X|Y$ with and without assuming PO. Following *Harrell (2001)*,

Using Bayes' Theorem, 

$$P(X = x | Y = j) = P(Y = j|X = x)P(X = x) / P(Y = j)$$

and so,

$$\hat{E}(X|Y = j) = \sum_{i=1}^{n} x_i \hat{P}_{jx_i}/g_j$$
where $g_j$ is the frequency of $Y = j$ and $\hat{P_jx_i}$ are the probability estimates of a univariate PO-model.

With the `rms` package (regression modeling strategies), we can produce said plot as follows:

```{r, message = FALSE, warning = FALSE}
library(rms)
plot.xmean.ordinaly(points ~ price, data = wines)
```

For our plot, we need to calculate the expected values conditional on the level of $Y$ ourselves. Without assuming PO, we can calculate the expected values by aggregating by the mean.

```{r}
agg <- aggregate(price ~ points, FUN = mean, data = wines)
agg$points <- as.numeric(agg$points)
```

To get the expected values under PO, we need to extract the probabilities first, i.e. run a univariate model. This is also a good way to show the two different ways of stating the model:

```{r, message = FALSE, warning = FALSE}
#univariate model
library(MASS)
pmPrice <- polr(as.factor(points) ~ price, data = wines)

#probabilities 
prob1 <- 1 / (1 + exp(-(pmPrice$zeta[1] - coef(pmPrice) * wines$price)))
prob2 <- 1 / (1 + exp(-(pmPrice$zeta[2] - coef(pmPrice) * wines$price))) 
prob3 <- 1 / (1 + exp(-(pmPrice$zeta[3] - coef(pmPrice) * wines$price))) 

#stated the other way, would write as e.g.
prob1 <- (exp(pmPrice$zeta[1] - coef(pmPrice) * wines$price)) / 
  (1 + (exp(pmPrice$zeta[1] - coef(pmPrice) * wines$price)))

#estimated expected values 
#(for inner terms, P(X|Y) are differences between probabilities)
e1 <- sum(wines$price *  prob1          / sum(wines$points == 0)) 
e2 <- sum(wines$price * (prob2 - prob1) / sum(wines$points == 1))
e3 <- sum(wines$price * (prob3 - prob2) / sum(wines$points == 2))
e4 <- sum(wines$price * (1 - prob3)     / sum(wines$points == 3))
```

Now we can just plug this into `ggplot`.

```{r, message = FALSE}
library(ggplot2)
ggplot(data = agg) + theme_minimal() +
  geom_line(aes(x = points, y = price)) +
  geom_point(aes(x = points, y = price), shape = 1, size = 3) +
  geom_line(aes(x = points, y = c(e1, e2, e3, e4)), linetype = 2) + 
  xlab("Points") + ylab("Price") + 
  labs(caption = "Testing Ordinality of Y.\nSolid Line: Simple Stratified Mean.
       Dashed Line: Estimated E(Y|X) given PO.")
```

Another way of checking the PO assumption is to stratify means on each predictor, and then compute "the logits of all proportions of the form $Y \geq j, j = 1, 2, ..., k$. When proportional odds holds, the differences in logits between different values of $j$ should be the same at all levels of $X$ because the model dictates that $logit(Y \leq j|X) - logit(Y \geq i|X) = a_j - a_i$ for any constant $X$ *(Harrell 2001)*.

To produce this plot, Harrell uses `summary.formula` of the `Hmisc` package to produce a plot like so:

```{r}
library(Hmisc)
pointInt <- as.integer(wines$points) - 1

sf <- function(y) {
  c(' Y >= 1 ' = qlogis (mean(y >= 1)), 
    ' Y >= 2 ' = qlogis (mean(y >= 2)))
}

s <- summary(pointInt ~ price + province, fun = sf, data = wines)

plot(s, which = 1:2, pch =1:2, xlab = 'logit ', 
     main = ' ', width.factor =1.5) 
```

To plot this using `ggplot2`, I will use `Hmisc`'s `cut2` to reproduce the same quantiles. I didn't quite understand `Hmisc`'s way of rounding, so it is beneficial that `cut2` returns the quantiles as factors -- this way, I won't have to do manual indexing.

```{r, warning = FALSE, message = FALSE}
library(tidyverse)

strataggPrice <- wines %>% 
  mutate(pointInt    = as.integer(points) - 1, 
         Interval    = Hmisc::cut2(price, g = 4)) %>%
  group_by(Interval) %>% 
  #two cutoffs in 0, 0|1, 1|2, 3
  summarize("Y>=1" = qlogis(mean(pointInt >= 1)), 
            "Y>=2" = qlogis(mean(pointInt >= 2)))

#by factor, aggregate without stratifying
strataggProv <- wines %>%
  mutate(pointInt = as.integer(points) - 1) %>% 
  group_by(province) %>%
  summarize("Y>=1" = qlogis(mean(pointInt >= 1)),
            "Y>=2" = qlogis(mean(pointInt >= 2))) %>% 
  rename(Interval = province) 

values <- rbind(strataggPrice, strataggProv)[, 2:3] %>% 
  gather() %>% select(value)

#long formats for ggplot
priceLong <- strataggPrice %>% 
  gather(key = "Shape", value = "value", "Y>=1", "Y>=2") %>%
  mutate(Shape = as.factor(Shape))

provLong  <- strataggProv  %>% 
  gather(key = "Shape", value = "value", "Y>=1", "Y>=2") %>%
  mutate(Shape = as.factor(Shape))

#overall is without any indexing
overall <- wines %>% 
  mutate(pointInt = as.integer(points) -1) %>% 
  select(pointInt) %>%
  mutate("Y>=1" = qlogis(mean(pointInt >= 1)), 
         "Y>=2" = qlogis(mean(pointInt >= 2))) %>% 
  slice(1) %>% 
  gather(key = "Shape", value = "value", "Y>=1", "Y>=2") %>% 
  select(-pointInt)

xmin <- min(values); xmax <- max(values); n <- nrow(strataggPrice)
```

Plugging this into `ggplot2`,

```{r}
ggplot() + theme_minimal()  +
  xlim(c(xmin - 1.2, xmax+0.2)) + 
  ylim(c(-1, nrow(values)-3)) +
  
  #provinces
  geom_segment(aes(x = rep(xmin, n), xend = rep(xmax, n), 
                   y = 3:(n+2), yend = 3:(n+2)), colour = "grey") +
  geom_point(data = provLong, aes(x = value, 
                                  y = rev(as.numeric(Interval)) + 2, 
                                  shape = Shape), size = 3) +
  geom_text(aes(label = rev(strataggProv$Interval), 
                x = rep(min(values) - 0.75, 4), y = 3:6)) +
  
  #prices
  geom_segment(aes(x = rep(xmin, n), xend = rep(xmax, n), 
                   y = (n+5):(2*n+4), yend = (n+5):(2*n+4)), 
               colour = "grey") +
  geom_point(data = priceLong, aes(x = value, 
                                   y = rev(as.numeric(Interval)) + n + 4, 
                                   shape = Shape), size = 3) +
  geom_text(aes(label = rev(strataggPrice$Interval), 
                x = rep(min(values) - 0.75), y = (n+5):(2*n+4))) +
  
  #overall
  geom_segment(aes(x = xmin, xend = xmax, 
                   y = 0, yend = 0), colour = "grey") +
  geom_point(data = overall, aes(x = value, y = 0, 
                                 shape = Shape), size = 3) +
  
  #x-titles
  geom_text(aes(label = c("Price", "Province", "Overall"), 
                x = rep(min(values) - 0.75, 3), y = c(13, 7, 1)),
            fontface = "bold") +
  
  #border
  geom_segment(aes(x = rep(c(xmin - 0.2, xmax + 0.2), 2), 
                   xend = c(xmin - 0.2, xmax + 0.2, 
                            xmax + 0.2, xmin - 0.2),
                   y = c(rep(-1, 2), -1, 13), 
                   yend = c(rep(13, 2), -1, 13))) +
  
  xlab("Logit") + 
  theme(axis.ticks.y = element_blank()) +
  theme(axis.text.y = element_blank())  +
  theme(axis.title.y = element_blank()) + 
  
  labs(caption = "PO is checked by examining\nvertical constancy of distances\nbetween the two symbols\n(Harrell, 2001).")
  
```

Lastly, unrelated to checking the PO assumption, I wanted to create a stacked effects display of cumulative probabilities. I usually create effects plots with the `effects` package like so

```{r, warning = FALSE, message = FALSE}
library(effects)
# fit the full model
fm <- polr(points ~ price + province, data = wines)

plot(Effect(focal.predictors = c("price", "province"), mod = fm,
     xlevels = list(price = seq(min(wines$price), max(wines$price), 
                                length.out = 100))), 
     style="stacked")
```

This is easily reproducible using `ggplot`. 

```{r}
#get predicted probabilities
predDat <- data.frame(
  price = rep(seq(min(wines$price), max(wines$price), length.out = 200), 
              length(unique(wines$province))),
  province = rep(levels(wines$province), each = 200)
)

predDat <- cbind(predDat, predict(fm, predDat, type = "probs"))

#long format for automatic fill
predLong <- predDat %>% gather(Points, value, "0", "1", "2", "3")

#colour palette for fill
f <- colorRampPalette(c("darkblue", "lightblue"))

#i use rev() here because it is more convenient than y-axis flip imo
ggplot(predLong, aes(x = price, y = value, fill = Points)) + 
  geom_area(position = position_stack(reverse = TRUE)) +
  scale_fill_manual(values = f(4)) + 
  geom_line(position = position_stack(reverse = TRUE)) +
  facet_wrap(~province, nrow = 1) +
  ylab("Probability") + xlab("Price") +
  theme_minimal() +
  theme(strip.text = element_text(size=14))
```

